{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This docuemnt and scripte is created by Harun-Ur-Rashid on Kaggle 6 years ago (around 2018).\n",
    "Link to original document: https://www.kaggle.com/code/harunshimanto/summarization-with-wine-reviews-using-spacy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "# &#127916; Introdruction Wine Reviews\n",
    "![Imgur](https://i.imgur.com/0GFdU23.png)\n",
    "> In this notebook, I will try to explore the Wine Reviews Dataset. It contains 130k  of reviews  in Wine Reviews. And at the end of this notebook, I will try to make simple text summarizer that will summarize given reviews. The summarized reviews can be used as a reviews title also.I will use Spacy as natural language processing library for handling this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8bd7a67c45605283a384c7ed3f1108d63c6341ce"
   },
   "source": [
    "## &#128203; Object Of This Project \n",
    "The objective of this project is to build a model that can create relevant summaries for reviews written on Wine reviews. This dataset contains above 130k  reviews, and is hosted on [Kaggle](https://www.kaggle.com/zynicide/wine-reviews)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "55579f5b396b1d6151fe0743a4156da1f4e2429b"
   },
   "source": [
    "## What Is Text Summarization?\n",
    "![Imgur](https://i.imgur.com/LLfNlBS.png)\n",
    "> Text summarization is the process of distilling the most important information from a source (or sources) to produce an abridged version for a particular user (or users) and task (or tasks)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a603f52d84bce68c606a8ba684f08908e935d812"
   },
   "source": [
    "## Types of Text Summarization Methods\n",
    "Text summarization methods can be classified into different types.\n",
    "![Imgur](https://i.imgur.com/J5KyMBJ.png)\n",
    "**i. Based on input type:**\n",
    "\n",
    "1. Single Document, where the input length is short. Many of the early summarization systems dealt with single document summarization.\n",
    "\n",
    "2. Multi Document, where the input can be arbitrarily long.\n",
    "\n",
    "**ii. Based on the purpose:**\n",
    "\n",
    "1. Generic, where the model makes no assumptions about the domain or content of the text to be summarized and treats all inputs as homogeneous. The majority of the work that has been done revolves around generic summarization.\n",
    "\n",
    "2. Domain-specific, where the model uses domain-specific knowledge to form a more accurate summary. For example, summarizing research papers of a specific domain, biomedical documents, etc.\n",
    "\n",
    "3. Query-based, where the summary only contains information which answers natural language questions about the input text.\n",
    "\n",
    "**iii. Based on output type:**\n",
    "\n",
    "1. Extractive, where important sentences are selected from the input text to form a summary. Most summarization approaches today are extractive in nature.\n",
    "\n",
    "2. Abstractive, where the model forms its own phrases and sentences to offer a more coherent summary, like what a human would generate. This approach is definitely a more appealing, but much more difficult than extractive summarization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "source": [
    "# 1. Import Packages \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "2860a7dca6861d4a750915c770365e06a1408ce2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.35.2.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from IPython.display import display\n",
    "import base64\n",
    "import string\n",
    "import re\n",
    "from collections import Counter\n",
    "from time import time\n",
    "# from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS as stopwords\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import heapq\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "%matplotlib inline\n",
    "\n",
    "stopwords = stopwords.words('english')\n",
    "sns.set_context('notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5e261260676c97cde87e171b9b049763740f63aa"
   },
   "source": [
    "# 2. Import Dataset \n",
    "> In this section, I will load the desired dataset for this notebook. This dataset has huge number of reviews. It will be hard to work with full dataset. So I will randomly sample the dataset into smaller chunks for easy purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "a53b6190504ccf397dd408b5882cfed485046b3e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>points</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aromas include tropical fruit, broom, brimston...</td>\n",
       "      <td>87</td>\n",
       "      <td>Nicosia 2013 VulkÃ  Bianco  (Etna)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is ripe and fruity, a wine that is smooth...</td>\n",
       "      <td>87</td>\n",
       "      <td>Quinta dos Avidagos 2011 Avidagos Red (Douro)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tart and snappy, the flavors of lime flesh and...</td>\n",
       "      <td>87</td>\n",
       "      <td>Rainstorm 2013 Pinot Gris (Willamette Valley)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pineapple rind, lemon pith and orange blossom ...</td>\n",
       "      <td>87</td>\n",
       "      <td>St. Julian 2013 Reserve Late Harvest Riesling ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Much like the regular bottling from 2012, this...</td>\n",
       "      <td>87</td>\n",
       "      <td>Sweet Cheeks 2012 Vintner's Reserve Wild Child...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Blackberry and raspberry aromas show a typical...</td>\n",
       "      <td>87</td>\n",
       "      <td>Tandem 2011 Ars In Vitro Tempranillo-Merlot (N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Here's a bright, informal red that opens with ...</td>\n",
       "      <td>87</td>\n",
       "      <td>Terre di Giurfo 2013 Belsito Frappato (Vittoria)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This dry and restrained wine offers spice in p...</td>\n",
       "      <td>87</td>\n",
       "      <td>Trimbach 2012 Gewurztraminer (Alsace)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Savory dried thyme notes accent sunnier flavor...</td>\n",
       "      <td>87</td>\n",
       "      <td>Heinz Eifel 2013 Shine GewÃ¼rztraminer (Rheinh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>This has great depth of flavor with its fresh ...</td>\n",
       "      <td>87</td>\n",
       "      <td>Jean-Baptiste Adam 2012 Les Natures Pinot Gris...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Soft, supple plum envelopes an oaky structure ...</td>\n",
       "      <td>87</td>\n",
       "      <td>Kirkland Signature 2011 Mountain CuvÃ©e Cabern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>This is a dry wine, very spicy, with a tight, ...</td>\n",
       "      <td>87</td>\n",
       "      <td>Leon Beyer 2012 Gewurztraminer (Alsace)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Slightly reduced, this wine offers a chalky, t...</td>\n",
       "      <td>87</td>\n",
       "      <td>Louis M. Martini 2012 Cabernet Sauvignon (Alex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>This is dominated by oak and oak-driven aromas...</td>\n",
       "      <td>87</td>\n",
       "      <td>Masseria Setteporte 2012 Rosso  (Etna)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Building on 150 years and six generations of w...</td>\n",
       "      <td>87</td>\n",
       "      <td>Mirassou 2012 Chardonnay (Central Coast)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          description  points  \\\n",
       "0   Aromas include tropical fruit, broom, brimston...      87   \n",
       "1   This is ripe and fruity, a wine that is smooth...      87   \n",
       "2   Tart and snappy, the flavors of lime flesh and...      87   \n",
       "3   Pineapple rind, lemon pith and orange blossom ...      87   \n",
       "4   Much like the regular bottling from 2012, this...      87   \n",
       "5   Blackberry and raspberry aromas show a typical...      87   \n",
       "6   Here's a bright, informal red that opens with ...      87   \n",
       "7   This dry and restrained wine offers spice in p...      87   \n",
       "8   Savory dried thyme notes accent sunnier flavor...      87   \n",
       "9   This has great depth of flavor with its fresh ...      87   \n",
       "10  Soft, supple plum envelopes an oaky structure ...      87   \n",
       "11  This is a dry wine, very spicy, with a tight, ...      87   \n",
       "12  Slightly reduced, this wine offers a chalky, t...      87   \n",
       "13  This is dominated by oak and oak-driven aromas...      87   \n",
       "14  Building on 150 years and six generations of w...      87   \n",
       "\n",
       "                                                title  \n",
       "0                  Nicosia 2013 VulkÃ  Bianco  (Etna)  \n",
       "1       Quinta dos Avidagos 2011 Avidagos Red (Douro)  \n",
       "2       Rainstorm 2013 Pinot Gris (Willamette Valley)  \n",
       "3   St. Julian 2013 Reserve Late Harvest Riesling ...  \n",
       "4   Sweet Cheeks 2012 Vintner's Reserve Wild Child...  \n",
       "5   Tandem 2011 Ars In Vitro Tempranillo-Merlot (N...  \n",
       "6    Terre di Giurfo 2013 Belsito Frappato (Vittoria)  \n",
       "7               Trimbach 2012 Gewurztraminer (Alsace)  \n",
       "8   Heinz Eifel 2013 Shine GewÃ¼rztraminer (Rheinh...  \n",
       "9   Jean-Baptiste Adam 2012 Les Natures Pinot Gris...  \n",
       "10  Kirkland Signature 2011 Mountain CuvÃ©e Cabern...  \n",
       "11            Leon Beyer 2012 Gewurztraminer (Alsace)  \n",
       "12  Louis M. Martini 2012 Cabernet Sauvignon (Alex...  \n",
       "13             Masseria Setteporte 2012 Rosso  (Etna)  \n",
       "14           Mirassou 2012 Chardonnay (Central Coast)  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = pd.read_csv(\"winemag data/winemag-data-130k-v2.csv\", nrows=5000,usecols =['points', 'title', 'description'],encoding='latin1')\n",
    "reviews = reviews.dropna()\n",
    "reviews.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "489093d68a8c094167a77cdb7479c184b3e20e87"
   },
   "source": [
    "# 3. Text preprocessing\n",
    "> In this step, I will be using Spacy for preprocessing text, in others words I will clearing not useful features from reviews title like punctuation, stopwords. For this task, there are two useful libraries available in Python. 1. NLTK 2. Spacy. In this notebook, I will be working with Spacy because it is very fast and has many useful features compared to NLTK. So without further do let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": false,
    "_uuid": "25fd7f9ae5fa5ca3efe698e99ba8e1631f7121a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-lg==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.7.1/en_core_web_lg-3.7.1-py3-none-any.whl (587.7 MB)\n",
      "     ---------------------------------------- 0.0/587.7 MB ? eta -:--:--\n",
      "     --------------------------------------- 2.9/587.7 MB 15.2 MB/s eta 0:00:39\n",
      "     --------------------------------------- 5.2/587.7 MB 13.3 MB/s eta 0:00:44\n",
      "      ------------------------------------- 10.5/587.7 MB 16.8 MB/s eta 0:00:35\n",
      "     - ------------------------------------ 18.1/587.7 MB 21.5 MB/s eta 0:00:27\n",
      "     - ------------------------------------ 23.9/587.7 MB 22.9 MB/s eta 0:00:25\n",
      "     - ------------------------------------ 27.8/587.7 MB 22.3 MB/s eta 0:00:26\n",
      "     -- ----------------------------------- 33.3/587.7 MB 22.7 MB/s eta 0:00:25\n",
      "     -- ----------------------------------- 39.1/587.7 MB 23.2 MB/s eta 0:00:24\n",
      "     --- ---------------------------------- 46.4/587.7 MB 24.4 MB/s eta 0:00:23\n",
      "     --- ---------------------------------- 53.5/587.7 MB 25.2 MB/s eta 0:00:22\n",
      "     --- ---------------------------------- 60.3/587.7 MB 26.0 MB/s eta 0:00:21\n",
      "     ---- --------------------------------- 67.4/587.7 MB 26.5 MB/s eta 0:00:20\n",
      "     ---- --------------------------------- 73.9/587.7 MB 26.8 MB/s eta 0:00:20\n",
      "     ----- -------------------------------- 81.3/587.7 MB 27.3 MB/s eta 0:00:19\n",
      "     ----- -------------------------------- 88.9/587.7 MB 27.8 MB/s eta 0:00:18\n",
      "     ------ ------------------------------- 96.7/587.7 MB 28.3 MB/s eta 0:00:18\n",
      "     ------ ------------------------------ 105.1/587.7 MB 29.1 MB/s eta 0:00:17\n",
      "     ------- ----------------------------- 114.0/587.7 MB 29.7 MB/s eta 0:00:16\n",
      "     ------- ----------------------------- 122.9/587.7 MB 30.3 MB/s eta 0:00:16\n",
      "     -------- ---------------------------- 131.3/587.7 MB 30.7 MB/s eta 0:00:15\n",
      "     -------- ---------------------------- 138.4/587.7 MB 30.9 MB/s eta 0:00:15\n",
      "     --------- --------------------------- 145.0/587.7 MB 30.9 MB/s eta 0:00:15\n",
      "     --------- --------------------------- 152.8/587.7 MB 31.1 MB/s eta 0:00:14\n",
      "     --------- --------------------------- 158.6/587.7 MB 30.9 MB/s eta 0:00:14\n",
      "     ---------- -------------------------- 163.1/587.7 MB 30.6 MB/s eta 0:00:14\n",
      "     ---------- -------------------------- 170.9/587.7 MB 30.9 MB/s eta 0:00:14\n",
      "     ----------- ------------------------- 178.8/587.7 MB 31.0 MB/s eta 0:00:14\n",
      "     ----------- ------------------------- 183.8/587.7 MB 30.7 MB/s eta 0:00:14\n",
      "     ------------ ------------------------ 191.9/587.7 MB 31.0 MB/s eta 0:00:13\n",
      "     ------------ ------------------------ 199.8/587.7 MB 31.2 MB/s eta 0:00:13\n",
      "     ------------- ----------------------- 207.9/587.7 MB 31.5 MB/s eta 0:00:13\n",
      "     ------------- ----------------------- 216.3/587.7 MB 31.7 MB/s eta 0:00:12\n",
      "     -------------- ---------------------- 224.9/587.7 MB 32.0 MB/s eta 0:00:12\n",
      "     -------------- ---------------------- 234.1/587.7 MB 32.3 MB/s eta 0:00:11\n",
      "     --------------- --------------------- 242.0/587.7 MB 32.4 MB/s eta 0:00:11\n",
      "     --------------- --------------------- 248.3/587.7 MB 32.3 MB/s eta 0:00:11\n",
      "     ---------------- -------------------- 255.1/587.7 MB 32.3 MB/s eta 0:00:11\n",
      "     ---------------- -------------------- 264.5/587.7 MB 32.9 MB/s eta 0:00:10\n",
      "     ----------------- ------------------- 272.9/587.7 MB 34.0 MB/s eta 0:00:10\n",
      "     ----------------- ------------------- 281.8/587.7 MB 34.3 MB/s eta 0:00:09\n",
      "     ------------------ ------------------ 290.5/587.7 MB 35.1 MB/s eta 0:00:09\n",
      "     ------------------ ------------------ 298.6/587.7 MB 35.5 MB/s eta 0:00:09\n",
      "     ------------------- ----------------- 307.0/587.7 MB 35.7 MB/s eta 0:00:08\n",
      "     ------------------- ----------------- 315.9/587.7 MB 36.0 MB/s eta 0:00:08\n",
      "     -------------------- ---------------- 324.8/587.7 MB 36.3 MB/s eta 0:00:08\n",
      "     -------------------- ---------------- 332.9/587.7 MB 36.6 MB/s eta 0:00:07\n",
      "     --------------------- --------------- 341.0/587.7 MB 36.7 MB/s eta 0:00:07\n",
      "     --------------------- --------------- 348.1/587.7 MB 36.9 MB/s eta 0:00:07\n",
      "     ---------------------- -------------- 354.4/587.7 MB 36.5 MB/s eta 0:00:07\n",
      "     ---------------------- -------------- 362.8/587.7 MB 36.5 MB/s eta 0:00:07\n",
      "     ----------------------- ------------- 371.5/587.7 MB 36.5 MB/s eta 0:00:06\n",
      "     ----------------------- ------------- 380.1/587.7 MB 36.4 MB/s eta 0:00:06\n",
      "     ------------------------ ------------ 389.0/587.7 MB 36.5 MB/s eta 0:00:06\n",
      "     ------------------------- ----------- 397.7/587.7 MB 36.5 MB/s eta 0:00:06\n",
      "     ------------------------- ----------- 404.8/587.7 MB 36.5 MB/s eta 0:00:06\n",
      "     -------------------------- ---------- 413.4/587.7 MB 36.8 MB/s eta 0:00:05\n",
      "     -------------------------- ---------- 418.9/587.7 MB 37.1 MB/s eta 0:00:05\n",
      "     -------------------------- ---------- 421.8/587.7 MB 36.7 MB/s eta 0:00:05\n",
      "     -------------------------- ---------- 423.9/587.7 MB 35.6 MB/s eta 0:00:05\n",
      "     -------------------------- ---------- 428.1/587.7 MB 35.1 MB/s eta 0:00:05\n",
      "     --------------------------- --------- 435.7/587.7 MB 35.1 MB/s eta 0:00:05\n",
      "     --------------------------- --------- 442.2/587.7 MB 35.0 MB/s eta 0:00:05\n",
      "     ---------------------------- -------- 447.2/587.7 MB 34.9 MB/s eta 0:00:05\n",
      "     ---------------------------- -------- 451.7/587.7 MB 34.4 MB/s eta 0:00:04\n",
      "     ---------------------------- -------- 458.8/587.7 MB 34.3 MB/s eta 0:00:04\n",
      "     ----------------------------- ------- 467.1/587.7 MB 34.3 MB/s eta 0:00:04\n",
      "     ----------------------------- ------- 476.1/587.7 MB 34.4 MB/s eta 0:00:04\n",
      "     ------------------------------ ------ 480.8/587.7 MB 33.9 MB/s eta 0:00:04\n",
      "     ------------------------------ ------ 488.6/587.7 MB 33.9 MB/s eta 0:00:03\n",
      "     ------------------------------- ----- 496.8/587.7 MB 33.7 MB/s eta 0:00:03\n",
      "     ------------------------------- ----- 505.4/587.7 MB 33.9 MB/s eta 0:00:03\n",
      "     -------------------------------- ---- 514.1/587.7 MB 34.2 MB/s eta 0:00:03\n",
      "     -------------------------------- ---- 521.4/587.7 MB 34.1 MB/s eta 0:00:02\n",
      "     --------------------------------- --- 528.2/587.7 MB 33.9 MB/s eta 0:00:02\n",
      "     --------------------------------- --- 536.1/587.7 MB 33.9 MB/s eta 0:00:02\n",
      "     ---------------------------------- -- 544.2/587.7 MB 33.7 MB/s eta 0:00:02\n",
      "     ---------------------------------- -- 551.8/587.7 MB 33.6 MB/s eta 0:00:02\n",
      "     ----------------------------------- - 560.7/587.7 MB 33.7 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 569.9/587.7 MB 33.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  578.0/587.7 MB 33.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  584.3/587.7 MB 33.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  587.5/587.7 MB 33.3 MB/s eta 0:00:01\n",
      "     ------------------------------------  587.5/587.7 MB 33.3 MB/s eta 0:00:01\n",
      "     ------------------------------------  587.5/587.7 MB 33.3 MB/s eta 0:00:01\n",
      "     ------------------------------------  587.5/587.7 MB 33.3 MB/s eta 0:00:01\n",
      "     ------------------------------------  587.5/587.7 MB 33.3 MB/s eta 0:00:01\n",
      "     ------------------------------------  587.5/587.7 MB 33.3 MB/s eta 0:00:01\n",
      "     ------------------------------------  587.5/587.7 MB 33.3 MB/s eta 0:00:01\n",
      "     ------------------------------------  587.5/587.7 MB 33.3 MB/s eta 0:00:01\n",
      "     ------------------------------------  587.5/587.7 MB 33.3 MB/s eta 0:00:01\n",
      "     ------------------------------------  587.5/587.7 MB 33.3 MB/s eta 0:00:01\n",
      "     ------------------------------------  587.5/587.7 MB 33.3 MB/s eta 0:00:01\n",
      "     ------------------------------------  587.5/587.7 MB 33.3 MB/s eta 0:00:01\n",
      "     ------------------------------------  587.5/587.7 MB 33.3 MB/s eta 0:00:01\n",
      "     ------------------------------------  587.5/587.7 MB 33.3 MB/s eta 0:00:01\n",
      "     ------------------------------------  587.5/587.7 MB 33.3 MB/s eta 0:00:01\n",
      "     ------------------------------------  587.5/587.7 MB 33.3 MB/s eta 0:00:01\n",
      "     ------------------------------------  587.5/587.7 MB 33.3 MB/s eta 0:00:01\n",
      "     ------------------------------------  587.5/587.7 MB 33.3 MB/s eta 0:00:01\n",
      "     ------------------------------------  587.5/587.7 MB 33.3 MB/s eta 0:00:01\n",
      "     ------------------------------------- 587.7/587.7 MB 22.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in c:\\users\\s9602\\github\\nlp-text-summarization\\venv\\lib\\site-packages (from en-core-web-lg==3.7.1) (3.7.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\s9602\\github\\nlp-text-summarization\\venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\s9602\\github\\nlp-text-summarization\\venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\s9602\\github\\nlp-text-summarization\\venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\s9602\\github\\nlp-text-summarization\\venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\s9602\\github\\nlp-text-summarization\\venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\s9602\\github\\nlp-text-summarization\\venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\s9602\\github\\nlp-text-summarization\\venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\s9602\\github\\nlp-text-summarization\\venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\s9602\\github\\nlp-text-summarization\\venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\s9602\\github\\nlp-text-summarization\\venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\s9602\\github\\nlp-text-summarization\\venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.12.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\s9602\\github\\nlp-text-summarization\\venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.66.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\s9602\\github\\nlp-text-summarization\\venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\s9602\\github\\nlp-text-summarization\\venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.9.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\s9602\\github\\nlp-text-summarization\\venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\s9602\\github\\nlp-text-summarization\\venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (75.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\s9602\\github\\nlp-text-summarization\\venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\s9602\\github\\nlp-text-summarization\\venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\s9602\\github\\nlp-text-summarization\\venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\s9602\\github\\nlp-text-summarization\\venv\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\s9602\\github\\nlp-text-summarization\\venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\s9602\\github\\nlp-text-summarization\\venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\s9602\\github\\nlp-text-summarization\\venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\s9602\\github\\nlp-text-summarization\\venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\s9602\\github\\nlp-text-summarization\\venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\s9602\\github\\nlp-text-summarization\\venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\s9602\\github\\nlp-text-summarization\\venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2024.8.30)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\s9602\\github\\nlp-text-summarization\\venv\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\s9602\\github\\nlp-text-summarization\\venv\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\s9602\\github\\nlp-text-summarization\\venv\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\s9602\\github\\nlp-text-summarization\\venv\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\s9602\\github\\nlp-text-summarization\\venv\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\s9602\\github\\nlp-text-summarization\\venv\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (13.8.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\s9602\\github\\nlp-text-summarization\\venv\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.19.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\s9602\\github\\nlp-text-summarization\\venv\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\s9602\\github\\nlp-text-summarization\\venv\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in c:\\users\\s9602\\github\\nlp-text-summarization\\venv\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\s9602\\github\\nlp-text-summarization\\venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\s9602\\github\\nlp-text-summarization\\venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.18.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\s9602\\github\\nlp-text-summarization\\venv\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\s9602\\github\\nlp-text-summarization\\venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.1.2)\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_lg\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "def normalize_text(text):\n",
    "    tm1 = re.sub('<pre>.*?</pre>', '', text, flags=re.DOTALL)\n",
    "    tm2 = re.sub('<code>.*?</code>', '', tm1, flags=re.DOTALL)\n",
    "    tm3 = re.sub('<[^>]+>©', '', tm1, flags=re.DOTALL)\n",
    "    return tm3.replace(\"\\n\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "a69744aafbd96fad87b1433c0cd3d40fbd4f04d2"
   },
   "outputs": [],
   "source": [
    "# in this step we are going to remove code syntax from text \n",
    "reviews['description_Cleaned_1'] = reviews['description'].apply(normalize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "d38a9fb0751391660bc33de4431ef2f2c521606b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before normalizing text-----\n",
      "\n",
      "Tart and snappy, the flavors of lime flesh and rind dominate. Some green pineapple pokes through, with crisp acidity underscoring the flavors. The wine was all stainless-steel fermented.\n",
      "\n",
      "After normalizing text-----\n",
      "\n",
      "Tart and snappy, the flavors of lime flesh and rind dominate. Some green pineapple pokes through, with crisp acidity underscoring the flavors. The wine was all stainless-steel fermented.\n"
     ]
    }
   ],
   "source": [
    "print('Before normalizing text-----\\n')\n",
    "print(reviews['description'][2])\n",
    "print('\\nAfter normalizing text-----\\n')\n",
    "print(reviews['description_Cleaned_1'][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0875039d74a5dc0636bbfb2eb93efcf7278c1f47"
   },
   "source": [
    "We can see a huge difference after normalizing our text. Now we can see our text is more manageable. This will help us to explore the reviews and later making summarizer.\n",
    "\n",
    "We are also seeing that there are some punctuation and stopwords. We also don't need them. In the first place, I don't remove them because we are gonna need this in future when we will make summarizer. So let's make another column that will store our normalized text without punctuation and stopwords."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1d3e99e4511e5e57a41935fe1432d93a2745cfe1"
   },
   "source": [
    "## 3.1 Clean text before feeding it to spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "64f118a88d5c7fb5fcf276f017fe6318b8b7c45e"
   },
   "outputs": [],
   "source": [
    "punctuations = '!\"#$%&\\'()*+,-/:;<=>?@[\\\\]^_`{|}~©'\n",
    "# Define function to cleanup text by removing personal pronouns, stopwords, and puncuation\n",
    "def cleanup_text(docs, logging=False):\n",
    "    texts = []\n",
    "    doc = nlp(docs, disable=['parser', 'ner'])\n",
    "    tokens = [tok.lemma_.lower().strip() for tok in doc if tok.lemma_ != '-PRON-']\n",
    "    tokens = [tok for tok in tokens if tok not in stopwords and tok not in punctuations]\n",
    "    tokens = ' '.join(tokens)\n",
    "    texts.append(tokens)\n",
    "    return pd.Series(texts)\n",
    "reviews['Description_Cleaned'] = reviews['description_Cleaned_1'].apply(lambda x: cleanup_text(x, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e9d814a5a03b4063b9e67efc2c6cf330ec8fc443"
   },
   "outputs": [],
   "source": [
    "print('Reviews description with punctuatin and stopwords---\\n')\n",
    "print(reviews['description_Cleaned_1'][0])\n",
    "print('\\nReviews description after removing punctuation and stopwrods---\\n')\n",
    "print(reviews['Description_Cleaned'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "05c4d720356799bcb929093c51fd9cb4af315317"
   },
   "source": [
    "Wow! See! Now our text looks much readable and less messy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4a925e4a30c7ace8cb844ddbbadb0bd2a848f596"
   },
   "source": [
    "# 4. Distribution of Points\n",
    "In this section, I will try understand the distribution of points. Here points mean number of upvote the \tdescription got in social media(such as facebook,twitter etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "e981d5761ded4aea90b302aa0cb0d6ac9ed7c27a"
   },
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "(reviews['points']).plot.hist(bins=30, figsize=(30,5), edgecolor='white',range=[0,150])\n",
    "plt.xlabel('Number of points', fontsize=17)\n",
    "plt.ylabel('frequency', fontsize=17)\n",
    "plt.tick_params(labelsize=15)\n",
    "plt.title('Number of points description', fontsize=17)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bb3caa428606c67c108d91c4ae7d4fa3f528d7a2"
   },
   "source": [
    "The description of points lies between 80 to 100 mostly. Majority of the description got points between 80 to 100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1642a971b3a627e10884a150714963ef2333e72b"
   },
   "source": [
    "# 5. Analyze reviews description\n",
    "In this section, I will try to analyze wine description. In Wine Reviews, the wine description plays a vital role. A good description can make your wine  stand out. It also helps get a reviews faster. Lastly, It will help you get some points. Let's see what we can find in the  wine description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "e68dde499af6efa3a8a942b362b8b095a7fcace1"
   },
   "outputs": [],
   "source": [
    "reviews['Title_len'] = reviews['Description_Cleaned'].str.split().str.len()\n",
    "rev = reviews.groupby('Title_len')['points'].mean().reset_index()\n",
    "trace1 = go.Scatter(\n",
    "    x = rev['Title_len'],\n",
    "    y = rev['points'],\n",
    "    mode = 'lines+markers',\n",
    "    name = 'lines+markers'\n",
    ")\n",
    "layout = dict(title= 'Average points by wine description Length',\n",
    "              yaxis = dict(title='Average points'),\n",
    "              xaxis = dict(title='wine description Length'))\n",
    "fig=dict(data=[trace1], layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "39abb8b4ce723d291e26f238ee6aad6a1e93ff27"
   },
   "source": [
    "# 6. Description Summarizer\n",
    "![Imgur](https://i.imgur.com/DrvohGg.jpg?1)\n",
    "> In this step, I will try to make a description summarizer. There is a huge amount of research going for text summarization. But I will try to do a simple technique for text summarization. The technique describes below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7f24b07ce1634f1a568f67bb6fd4a881c12fa113"
   },
   "source": [
    "### 6.1 Convert Paragraphs to Sentences\n",
    "> We first need to convert the whole paragraph into sentences. The most common way of converting paragraphs to sentences is to split the paragraph whenever a period is encountered.\n",
    "\n",
    "### 6.2 Text Preprocessing\n",
    "> After converting paragraph to sentences, we need to remove all the special characters, stop words and numbers from all the sentences.\n",
    "\n",
    "### 6.3 Tokenizing the Sentences\n",
    "> We need to tokenize all the sentences to get all the words that exist in the sentences\n",
    "\n",
    "### 6.4 4. Find Weighted Frequency of Occurrence\n",
    "> Next we need to find the weighted frequency of occurrences of all the words. We can find the weighted frequency of each word by dividing its frequency by the frequency of the most occurring word.\n",
    "\n",
    "### 6.5 Replace Words by Weighted Frequency in Original Sentences\n",
    "> The final step is to plug the weighted frequency in place of the corresponding words in original sentences and finding their sum. It is important to mention that weighted frequency for the words removed during preprocessing (stop words, punctuation, digits etc.) will be zero and therefore is not required to be added\n",
    "\n",
    "### 6.6 Sort Sentences in Descending Order of Sum\n",
    "> The final step is to sort the sentences in inverse order of their sum. The sentences with highest frequencies summarize the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "231232c4be343eb6c6812ca26069bc437c422be8"
   },
   "outputs": [],
   "source": [
    "# this is function for text summarization\n",
    "def generate_summary(text_without_removing_dot, cleaned_text):\n",
    "    sample_text = text_without_removing_dot\n",
    "    doc = nlp(sample_text)\n",
    "    sentence_list=[]\n",
    "    for idx, sentence in enumerate(doc.sents): # we are using spacy for sentence tokenization\n",
    "        sentence_list.append(re.sub(r'[^\\w\\s]','',str(sentence)))\n",
    "\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "    word_frequencies = {}  \n",
    "    for word in nltk.word_tokenize(cleaned_text):  \n",
    "        if word not in stopwords:\n",
    "            if word not in word_frequencies.keys():\n",
    "                word_frequencies[word] = 1\n",
    "            else:\n",
    "                word_frequencies[word] += 1\n",
    "\n",
    "\n",
    "    maximum_frequncy = max(word_frequencies.values())\n",
    "\n",
    "    for word in word_frequencies.keys():  \n",
    "        word_frequencies[word] = (word_frequencies[word]/maximum_frequncy)\n",
    "\n",
    "\n",
    "    sentence_scores = {}  \n",
    "    for sent in sentence_list:  \n",
    "        for word in nltk.word_tokenize(sent.lower()):\n",
    "            if word in word_frequencies.keys():\n",
    "                if len(sent.split(' ')) < 30:\n",
    "                    if sent not in sentence_scores.keys():\n",
    "                        sentence_scores[sent] = word_frequencies[word]\n",
    "                    else:\n",
    "                        sentence_scores[sent] += word_frequencies[word]\n",
    "\n",
    "\n",
    "    summary_sentences = heapq.nlargest(7, sentence_scores, key=sentence_scores.get)\n",
    "\n",
    "    summary = ' '.join(summary_sentences)\n",
    "    print(\"Original Text:\\n\")\n",
    "    print(text_without_removing_dot)\n",
    "    print('\\n\\nSummarized text:\\n')\n",
    "    print(summary)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ac545db73e4e8f7b7528a9743d163e78345d1130"
   },
   "source": [
    "Now we have written the function let's try to summarize some descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "716d14346ed32a3530b28ff69e656b304344c054"
   },
   "outputs": [],
   "source": [
    "generate_summary(reviews['description_Cleaned_1'][8], reviews['Description_Cleaned'][8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "6626cafc63770b6c170e956ec5bdbd0616424d7c"
   },
   "outputs": [],
   "source": [
    "generate_summary(reviews['description_Cleaned_1'][100], reviews['Description_Cleaned'][100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "f8b4740ed18aea47c70b34fcc993f518b443c330"
   },
   "outputs": [],
   "source": [
    "generate_summary(reviews['description_Cleaned_1'][500], reviews['Description_Cleaned'][500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bd90fbd12a610786d89fe5d6af135dcad3d97132"
   },
   "source": [
    "That's awesome! We successfully made a simple winemag description summarizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "65c5b5c8280fdd4dc9b16fad86669cc444b5b02c"
   },
   "source": [
    "# 7. Conclusion\n",
    "> Thanks for reading this notebook. If you have any suggestion feel free to reach me in the comment. And don't forget to upvote. 👍\n",
    "> Stay in touch for more update. Thank you. &#128526;"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1442,
     "sourceId": 8172,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 18195,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
